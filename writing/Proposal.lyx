#LyX 1.4.3-5 created this file. For more info see http://www.lyx.org/
\lyxformat 245
\begin_document
\begin_header
\textclass article
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize default
\spacing double
\papersize letterpaper
\use_geometry true
\use_amsmath 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Title
Real-time motion planning for manipulator systems in cluttered environments
\end_layout

\begin_layout Author
John D.
 Yamokoski
\end_layout

\begin_layout Quotation

\newpage
Everything should be made as simple as possible, but not one bit simpler.
 
\series bold
-Albert Einstein
\end_layout

\begin_layout Abstract
This is my abstract.
\end_layout

\begin_layout Standard

\newpage

\begin_inset LatexCommand \tableofcontents{}

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
In the Orthopedic Biomechanics laboratory, we are developing a novel X-ray
 imaging platform which will be based on the coordinated motion of two 6-DOF
 commercial manipulators (Figure 1).
 However, robots operating in close proximity to humans is a difficult control
 problem.
 From a control design perspective, the robot workspace becomes cluttered
 with dynamic obstacles with which collisions are not acceptable.
 Even a seemingly minor collision between robot and human could cause serious
 injury or in the extreme case death.
\end_layout

\begin_layout Standard
Better integration of planning and control has been recognized as a frontier
 area of robotics research [ref].
\end_layout

\begin_layout Section
Problem definition and related work 
\end_layout

\begin_layout Standard
Autonomy in robotics is a tough problem.
 With non-autonomous systems, we must specify exactly how to do a particular
 task which is often laborious and error-prone.
 In contrast, complete autonomy would allow us to simply specify what needs
 to be done and the system would intelligently fill in the missing steps.
 There are still many outstanding problems yet to be solved on the road
 to autonomous systems.
 One in particular, known as the motion planning problem, has received a
 lot of attention over the years.
 Its is concerned with finding algorithms which provide robots the ability
 to plan their own movements given a few conditions or constraints by the
 user.
 All current solutions can be categorized as being either global or local
 methods, or either exact or approximate methods respectively.
 
\end_layout

\begin_layout Standard
Global or exact methodologies are guaranteed to find a solution to the motion
 planning problem if one exists.
 Usually these methods attempt to explicitly represent the free configuration
 space of the manipulator system.
 First introduced by Lozano-Pérez 
\begin_inset LatexCommand \cite{Lozano-Perez1983a}

\end_inset

, the configuration space 
\begin_inset Formula $\mathcal{C}$
\end_inset

 abstracts the motion planning problem by encoding the robot's 
\begin_inset Formula $n$
\end_inset

 degree of freedom as independent parameters of an 
\begin_inset Formula $n$
\end_inset

-dimensional manifold.
 The free configuration space 
\begin_inset Formula $\mathcal{C}_{free}$
\end_inset

 is simply the subset 
\begin_inset Formula $\mathcal{C}_{free}\subseteq\mathcal{C}$
\end_inset

 which is void of any obstacles lifted into
\begin_inset Formula $\mathcal{C}$
\end_inset

.
 However, they have several disadvantages.
 The algorithms necessary for global methods are computationally intensive.
 Also, the computational cost increases quickly as a function of the degree
 of freedom of the system in question.
 In fact, the theoretical complexity of exact methods is exponential in
 the number of degrees of freedom of the robot, making these methods intractable
 for real-time planning or collision avoidance 
\begin_inset LatexCommand \cite{de2000-Computational}

\end_inset

.
 The alternative is vast number of local or approximate methods {ref}.
 These are less computationally demanding and have been integrated into
 a real-time robotic control system {ref}.
 However, what makes these methods computationally efficient also becomes
 their main disadvantage: unlike exact or global methods, these can not
 guarantee to find a solution if one exists.
 Examples of seemingly simple yet practical workspaces can be constructed
 to demonstrate where each local method can fail {ref}.
 
\end_layout

\begin_layout Standard
Despite this major shortcoming, local and approximate methods have thus
 far provided the best answer to real-time planning and control.
 Is it impractical to demand optimal or exact solutions from a real-time
 system? It depends on the time scale involved.
 Consider a chess playing robot such as Deep Blue.
 Each turn it must formulate an action or plan based on the current positions
 of the pieces on the chess board.
 The game-tree complexity of chess is now evaluated at approximately 10123.
 (As a comparison, the number of atoms in the Universe is estimated to be
 between 4x1079 and 1081.) Computing an optimal series of actions, which
 equates to finding an optimal path in this tree, is simply not possible.
 
\end_layout

\begin_layout Subsection
Problem definition 
\end_layout

\begin_layout Standard
This research is concerned with real-time motion planning for manipulator
 systems in the real world.
 This statement requires several points of clarification.
 Working in reverse, the real world 
\begin_inset Formula $\mathcal{W}$
\end_inset

 of the manipulator system referes to a three dimensional Euclidean space,
\begin_inset Formula $\mathcal{W}=\mathbb{R}^{3}$
\end_inset

.
 All objects in this world can be classified as either an obstacle, 
\begin_inset Formula $\mathcal{O}$
\end_inset

, or robot, 
\begin_inset Formula $\mathcal{R}$
\end_inset

.
 Both sets of objects are considered closed subsets of 
\begin_inset Formula $\mathcal{W}$
\end_inset

.
 The difference, however, is that bodies in 
\begin_inset Formula $\mathcal{R}$
\end_inset

 are controllable via the motion plan.
 As with many problems, the choice of object representation is often dictated
 by the operations performed on them.
 It is not surprising then that there are many proposals concerning the
 best way to model objects.
 A sample of these methods include parametric surfaces, semi-algebraic models,
 and unions of simple geometric primitives (see 
\begin_inset LatexCommand \cite{Hoffmann1989}

\end_inset

 for a thorough review of solid and boundary representations).
 Therefore, choice of a particular object model will be deferred until discussio
n of the solution techniques.
\end_layout

\begin_layout Standard
The immediate application of this work will be the real-time planning module
 for a novel, dual-arm X-ray imaging system being developed by the Orhtopedic
 Biomechanics Laboratory at the University of Florida.
 However, to retain generality, this work will also be applicable to any
 manipulator system composed of one or several independent robotic manipulators.
 It will be assumed that each manipulator 
\begin_inset Formula $\mathcal{\mathit{\mathcal{R}_{i}}\subseteq R}$
\end_inset

 will be composed of a series of rigid bodies 
\begin_inset Formula $\mathcal{A}_{j}\subseteq\mathcal{A}$
\end_inset

 connected end-to-end by rigid joints.
\end_layout

\begin_layout Standard
Given a set of models, initial conditions, and ability to sense changes
 in the objects of 
\begin_inset Formula $\mathcal{W}$
\end_inset

, this research is is concerned with developing an algorithm to compute,
 in real-time, a series of action sequences to be carried out by the manipulator
 system.
 Furthermore, the planned action sequence should obey physical limits of
 manipulator system and ultimately converge to some goal location or metric.
\end_layout

\begin_layout Subsection
Related work 
\end_layout

\begin_layout Subsubsection
Early work 
\end_layout

\begin_layout Standard
The first motion planning modules in real-time control systems focused on
 separating the automatic navigation problem into two sequential stages,
 planning and control.
 This separation was primarily due the computational compelxity of early
 planning algorithms.
 Examples, results, problems.
 Any vanilla APF-based controller is classified as a local planning method.
 Global methods, (properties of global methods), include (examples of global
 methods).
 
\end_layout

\begin_layout Subsubsection
Artificial potential fields 
\end_layout

\begin_layout Standard
Artificial potential field (APF) techniques were an attempt to address the
 planning and control problems simultaneously.
 Khatib was the first to propose APFs as a technique to achieve real-time
 collision avoidance 
\begin_inset LatexCommand \cite{Khatib1986-90}

\end_inset

.
 The idea was to endow obstacles and a goal location with virtual repulsive
 and attractive potentials respectively.
 A virtual control force is generated by summing the negative gradient of
 each potential field at the robot's end effector.
 Placed in a discrete control system, the composite potential field can
 be updated in every cycle to account for not only static but also dynamic
 obstacles.
 This yields local planning and collision avoidance behavior for the robot.
 The primary drawback of Khatib's initial contribution is the potential
 for local minima (e.g.
 Figure 1) created by the interaction of obstacle fields.
 Subsequent work has sought to achieve global performance by minimizing
 the effect or eliminating the local minima.
 For instance, various heuristics have been employed to deal with local
 minima.
 By applying recently developed Lyapunov design techniques, Mbede et al.
 designed a uniformly, ultimately bounded regulator using a fuzzy rule system
 to reason about the APF output 
\begin_inset LatexCommand \cite{Mbede2003-249}

\end_inset

.
 They combined this with a neural network to deal with any other dynamic
 model uncertainties.
 Hybrid force/velocity method, switching system, desired velocity signal
 generated by the negative gradient of a potential field function 
\begin_inset LatexCommand \cite{Palejiya2006-745}

\end_inset

.
 
\end_layout

\begin_layout Standard
Impedance control is a method to regulate the mechanical impedance of an
 end-effector of a robot manipulator in a desired value according to a given
 task.
 It can specify the desirable response of the end-effector to an external
 force normally generated from contact with the environment.
 An APF generates virtual forces on the manipulator, Tsuji and Kaneko extended
 impedance control is one of the most important frameworks to control the
 interaction between the manipulators and the environment.
 Under the conventional impedance control method, it is difficult to cope
 effectively with such situations, since no external force is exerted until
 the end-effector makes contact with objects.
 In this paper, we apply the vision-based impedance control to a redundant
 manipulator and thus propose a non-contact impedance control which can
 utilize kinematic redundancy.
 This method can control the virtual impedance between the object and multiple
 points set on the arm, including the end-effector, so that the virtual
 interaction between the whole arm and the environment can be considered.
\end_layout

\begin_layout Subsubsection
Elastic strips
\end_layout

\begin_layout Subsubsection
Strategy-based
\end_layout

\begin_layout Section
Proposed work
\end_layout

\begin_layout Subsection
Overview and timeline
\end_layout

\begin_layout Standard
This research is concerned with real-time motion planning for manipulator
 systems in the real world.
 The immediate application of this work will be the real-time planning module
 for a novel, dual-arm X-ray imaging system being developed by the Orhtopedic
 Biomechanics Laboratory at the University of Florida.
\end_layout

\begin_layout Itemize
This work has three areas of thrust - Theoretical development, implementation
 and experimentation, and education.
\end_layout

\begin_layout Itemize
Research is not an isolated activity, therefore it is paramount that this
 work be evaluated by members of the robotic community for its contribution
 to motion planning research as well as by the biomechanics community for
 its role as a new diagnostic tool.
\end_layout

\begin_layout Subsection
Specific aim 1 - Theoretical development of a real-time planning system
\end_layout

\begin_layout Subsection
Specific aim 2 - Implentation and evaluation on the GatorRay Imaging System
\end_layout

\begin_layout Standard
Experimental evaluation of any robotic system which,
\end_layout

\begin_layout Enumerate
Provably small chance, with an adequate confidence level, of failure.
\end_layout

\begin_layout Enumerate
In the unlikely event of failure, the control system will minimize injuries
 to the person.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
The core hardware components required to research the robotic imaging system
 include a pair of six axis robot arms, a real-time motion capture system,
 and a digital video system as detailed in section I.3.
 Significant progress already has been made in the design and implementation
 of the system?s control software.
 Preliminary studies performed to assess the measurement capabilities of
 the PA10-6C robot (e.g.
 static and dynamic accuracy and precision) utilized a control system implemente
d in Linux with the hard real-time software framework provided by the OROCOS
 project [61] and RTAI [83].
 This control framework integrated a real-time motion controller for one
 robot and a real-time target generator driven by inputs from the motion
 capture system.
 This early system demonstrated the integration of the two major components
 of the final system ? robots and motion capture.
 Lessons learned from this early design motivate the adoption of more rigorous
 software design tools, including component-based software engineering (CBSE)
 principles.
 Component-based software development provides several key benefits when
 applied to the design of robotic software control systems, particularly
 in software reusability and modularity.
 
\end_layout

\begin_layout Standard
CBSE software components are reusable by design and several open-source
 projects devoted to CBSE use in robotic systems host repositories of freely
 available components [59, 62].
 Devel-opers from around the world have submitted components for common
 hardware or sensor sys-tems as well as algorithms common to robotics control.
 Where possible, components from these repositories will be used in the
 re-design of our control system, accelerating development time.
 For components that do not yet exist (e.g.
 interface to the PA10-6C robot), components from similar categories will
 be used as templates and modified as needed.
 All novel components cre-ated during the proposed work will be submitted
 to the same open-source repositories.
 
\end_layout

\begin_layout Standard
After all necessary components have been created or acquired, they will
 be assembled into a cohesive software control framework.
 This final framework also will be modular to allow future integration of
 new systems (e.g.
 X-ray hardware or force sensors on the robot arms).
\end_layout

\begin_layout Standard
Evaluation: Performance of the control software will be evaluated using
 a variety of prepro-grammed trajectories (figure 8?s) and real-time tracking
 tasks (e.g.
 having one robot track a mo-tion capture marker array placed on the other
 robot).
 Quantitative outcome metrics will charac-terize communication and robot
 motion latencies in addition to demonstration of all required control,
 communication and measurement functionality for the integrated robotic,
 motion cap-ture, and video recording systems.
\end_layout

\begin_layout Standard
Potential difficulties and workarounds: Preliminary experience integrating
 these systems es-tablishes the feasibility of the approach.
 However, the robotic imaging platform is a complex system.
 The P.I.
 has secured the cooperation of Prof.
 Manuel Bermudez in the U.F.
 Computer and Information Science and Engineering Department to assist in
 the software design, implemen-tation and testing (see letter of support
 from Prof.
 Bermudez).
\end_layout

\begin_layout Subsection
Educational thrust
\end_layout

\begin_layout Standard
\begin_inset LatexCommand \bibtex[plain]{Proposal_Library}

\end_inset


\end_layout

\end_body
\end_document
